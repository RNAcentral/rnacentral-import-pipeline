# -*- coding: utf-8 -*-

"""
Copyright [2009-2021] EMBL-European Bioinformatics Institute
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
"""

import logging
import re
from pathlib import Path

import click
import polars as pl

from rnacentral_pipeline.databases.expressionatlas import configuration, parser, sdrf
from rnacentral_pipeline.databases.expressionatlas.helpers import find_all_taxids
from rnacentral_pipeline.writers import entry_writer

LOGGER = logging.getLogger(__name__)


@click.group("expressionatlas")
def cli():
    """
    Commands for parsing expression atlas data
    """


@cli.command("parse")
@click.argument("genes_mapped", type=click.File("r"))
@click.argument("lookup", type=click.Path())
@click.argument(
    "output",
    default=".",
    type=click.Path(writable=True, dir_okay=True, file_okay=False),
)
def process_csv(genes_mapped, lookup, output):
    """
    Process the csv generated by linking EA data to rnc data
    """
    entries = parser.parse(genes_mapped, lookup)

    with entry_writer(Path(output)) as writer:
        try:
            writer.write(entries)
        except ValueError:
            print("No entries from this chunk")


@cli.command("get-taxids")
@click.argument(
    "directory", type=click.Path(exists=True, file_okay=False, dir_okay=True)
)
@click.argument("output")
def get_taxids(directory, output):
    """
    Find all condensed SDRF files in the subdirectory, and parse out all possible taxids.
    Write these out to a file so we can query with them later.

    Args:
        directory: The path to the top-level directory within which are all Expression atlas
            experiments.
        output: A text file that will have one taxid per line, ready to be used in a future
            sql query
    """
    taxids = find_all_taxids(directory)
    with open(output, "w") as out:
        for t in taxids:
            out.write(f"{t}\n")

    LOGGER.info(f"Found {len(taxids)} unique taxids to search for")


@cli.command("parse-dir")
@click.argument(
    "directory", type=click.Path(exists=True, file_okay=False, dir_okay=True)
)
@click.argument("lookup", type=click.Path())
@click.argument("output", type=click.Path())
def parse_dir(directory, lookup, output):
    """
    Look at the files within a directory and parse them appropriately

    This will parse down to a urs_taxid <> experiment mapping
    The next parsing stage will create entries using the lookup
    """
    directory = Path(directory)
    configurations = list(directory.glob("*configuration.xml"))
    assert len(configurations) == 1
    config_file = configurations[0]
    config = configuration.parse_config(config_file)
    input("wait...")
    if config.exp_type == "rnaseq_mrna_differential":
        analytics = list(directory.glob("*analytics.tsv"))
        assert len(analytics) == 1
        analytics_file = analytics[0]

        sdrfs = list(directory.glob("*condensed-sdrf.tsv"))
        assert len(sdrfs) == 1
        sdrf = sdrfs[0]
        print(analytics_file)
        try:
            hits = parser.parse_differential(analytics_file, sdrf, lookup)
        except ValueError:
            LOGGER.error("Failed to parse differential experiment %s", analytics_file)
            hits = pl.DataFrame()
    elif config.exp_type == "rnaseq_mrna_baseline":
        ## There is a transcripts tpms file which we don't want, so grab both with
        ## pathlib glob, then filter to only get the one we want
        tpms = list(directory.glob(r"*-tpms.tsv"))
        tpms = list(filter(lambda x: re.match(".*\d+-tpms\.tsv$", str(x)), tpms))[0]

        sdrfs = list(directory.glob("*condensed-sdrf.tsv"))
        assert len(sdrfs) == 1
        sdrf = sdrfs[0]
        try:
            hits = parser.parse_baseline(tpms, sdrf, lookup)
        except ValueError:
            hits = pl.DataFrame()
            LOGGER.error("failed to parse baseline experiment %s", tpms)

    hits.write_ndjson(output)
